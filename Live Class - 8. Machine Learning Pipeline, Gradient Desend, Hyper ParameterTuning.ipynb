{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0145082a",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6702102f",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7279517867753162\n"
     ]
    }
   ],
   "source": [
    "#cReate a pipeline that standardize the data then creates a model\n",
    "\n",
    "from pandas import read_csv\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#load data\n",
    "#url = \"https://github.com/dsrscientist/dataset1/blob/master/pima_indian_diabetes.csv\"\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "\n",
    "#DataFrame\n",
    "dataframe = read_csv(\"pima_indian_diabetes.csv\", names = names)\n",
    "array = dataframe.values\n",
    "\n",
    "x= array[:,0:8]\n",
    "y= array[:,8]\n",
    "\n",
    "#create pipeline\n",
    "estimators =[]\n",
    "estimators.append(('Standardize',StandardScaler()))\n",
    "estimators.append(('dtc',DecisionTreeClassifier()))\n",
    "model = Pipeline(estimators)\n",
    "\n",
    "#evaluate pipeline\n",
    "result = cross_val_score(model, x,y, cv=5)\n",
    "print(result.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fcec90",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Gradient Descent Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f098c60f",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDRegressor: nan (nan)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rima Das\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\Rima Das\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "5 fits failed out of a total of 5.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rima Das\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py\", line 194, in _get_penalty_type\n",
      "    return PENALTY_TYPES[penalty]\n",
      "KeyError: '12'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rima Das\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rima Das\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\Rima Das\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py\", line 1537, in fit\n",
      "    return self._fit(\n",
      "  File \"C:\\Users\\Rima Das\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py\", line 1472, in _fit\n",
      "    self._validate_params()\n",
      "  File \"C:\\Users\\Rima Das\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py\", line 158, in _validate_params\n",
      "    self._get_penalty_type(self.penalty)\n",
      "  File \"C:\\Users\\Rima Das\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py\", line 196, in _get_penalty_type\n",
      "    raise ValueError(\"Penalty %s is not supported. \" % penalty) from e\n",
      "ValueError: Penalty 12 is not supported. \n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    }
   ],
   "source": [
    "# importing libraries\n",
    "from sklearn import linear_model\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#loading Data\n",
    "x= load_boston()\n",
    "#x = pd.read_csv('BostonHousing.csv')\n",
    "data =pd.DataFrame(x.data,columns = x.feature_names)\n",
    "y = x.target\n",
    "\n",
    "#creating a model\n",
    "pipe = []\n",
    "pipe.append(('SC', StandardScaler()))\n",
    "pipe.append(('PCA', PCA(n_components=8)))\n",
    "pipe.append(('SGD', SGDRegressor(alpha=0.1, learning_rate = 'optimal', max_iter=400, penalty='12'))) # Deafult\n",
    "model = Pipeline(pipe)\n",
    "\n",
    "#cross validation score\n",
    "cv_results = cross_val_score(model,data, y , cv=5)\n",
    "msg = \"%s: %f (%f)\" % ('SGDRegressor', cv_results.mean(), cv_results.std())\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64133413",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier: 0.706667 (0.155492)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "x=load_iris()\n",
    "data = pd.DataFrame(x.data, columns = x.feature_names)\n",
    "y = x.target\n",
    "\n",
    "#creating model\n",
    "model = SGDClassifier()\n",
    "\n",
    "#cross validation score\n",
    "cv_results = cross_val_score(model, data, y, cv=5)\n",
    "msg = \"%s: %f (%f)\" % ('SGDClassifier', cv_results.mean(), cv_results.std())\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87937be0",
   "metadata": {},
   "source": [
    "# Hyper Parameter Tuning :GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a050da39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(estimator=Ridge(),\n",
      "             param_grid={'alpha': [1, 0.01, 0.001, 0.0001, 0]})\n",
      "0.4823231384163485\n",
      "0.0001\n",
      "{'alpha': 0.0001}\n"
     ]
    }
   ],
   "source": [
    "#Grid Search for Algorith Tuning\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Load the diabetes datasets\n",
    "dataset = datasets.load_diabetes()\n",
    "\n",
    "#prepare a range of alpha values to test\n",
    "#alphas = np.array([1,0.01,0.001,0.0001,0])\n",
    "alphavalues ={'alpha':[1,0.01,0.001,0.0001,0]}\n",
    "\n",
    "#create and fit a ridge regression model, testing each alpha\n",
    "model =Ridge()\n",
    "\n",
    "#grid = GridSearchCv(estimator=model, param_grid=dict(aplha=aplhas))\n",
    "grid = GridSearchCV(estimator=model, param_grid = alphavalues)\n",
    "grid.fit(dataset.data, dataset.target)\n",
    "print(grid)\n",
    "\n",
    "#summarise the result of grid serach\n",
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_.alpha)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732828f7",
   "metadata": {},
   "source": [
    "### Now appling the alpha in the actual dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5520dc3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.03807591  0.05068012  0.06169621 ... -0.00259226  0.01990842\n",
      "  -0.01764613]\n",
      " [-0.00188202 -0.04464164 -0.05147406 ... -0.03949338 -0.06832974\n",
      "  -0.09220405]\n",
      " [ 0.08529891  0.05068012  0.04445121 ... -0.00259226  0.00286377\n",
      "  -0.02593034]\n",
      " ...\n",
      " [ 0.04170844  0.05068012 -0.01590626 ... -0.01107952 -0.04687948\n",
      "   0.01549073]\n",
      " [-0.04547248 -0.04464164  0.03906215 ...  0.02655962  0.04452837\n",
      "  -0.02593034]\n",
      " [-0.04547248 -0.04464164 -0.0730303  ... -0.03949338 -0.00421986\n",
      "   0.00306441]] [151.  75. 141. 206. 135.  97. 138.  63. 110. 310. 101.  69. 179. 185.\n",
      " 118. 171. 166. 144.  97. 168.  68.  49.  68. 245. 184. 202. 137.  85.\n",
      " 131. 283. 129.  59. 341.  87.  65. 102. 265. 276. 252.  90. 100.  55.\n",
      "  61.  92. 259.  53. 190. 142.  75. 142. 155. 225.  59. 104. 182. 128.\n",
      "  52.  37. 170. 170.  61. 144.  52. 128.  71. 163. 150.  97. 160. 178.\n",
      "  48. 270. 202. 111.  85.  42. 170. 200. 252. 113. 143.  51.  52. 210.\n",
      "  65. 141.  55. 134.  42. 111.  98. 164.  48.  96.  90. 162. 150. 279.\n",
      "  92.  83. 128. 102. 302. 198.  95.  53. 134. 144. 232.  81. 104.  59.\n",
      " 246. 297. 258. 229. 275. 281. 179. 200. 200. 173. 180.  84. 121. 161.\n",
      "  99. 109. 115. 268. 274. 158. 107.  83. 103. 272.  85. 280. 336. 281.\n",
      " 118. 317. 235.  60. 174. 259. 178. 128.  96. 126. 288.  88. 292.  71.\n",
      " 197. 186.  25.  84.  96. 195.  53. 217. 172. 131. 214.  59.  70. 220.\n",
      " 268. 152.  47.  74. 295. 101. 151. 127. 237. 225.  81. 151. 107.  64.\n",
      " 138. 185. 265. 101. 137. 143. 141.  79. 292. 178.  91. 116.  86. 122.\n",
      "  72. 129. 142.  90. 158.  39. 196. 222. 277.  99. 196. 202. 155.  77.\n",
      " 191.  70.  73.  49.  65. 263. 248. 296. 214. 185.  78.  93. 252. 150.\n",
      "  77. 208.  77. 108. 160.  53. 220. 154. 259.  90. 246. 124.  67.  72.\n",
      " 257. 262. 275. 177.  71.  47. 187. 125.  78.  51. 258. 215. 303. 243.\n",
      "  91. 150. 310. 153. 346.  63.  89.  50.  39. 103. 308. 116. 145.  74.\n",
      "  45. 115. 264.  87. 202. 127. 182. 241.  66.  94. 283.  64. 102. 200.\n",
      " 265.  94. 230. 181. 156. 233.  60. 219.  80.  68. 332. 248.  84. 200.\n",
      "  55.  85.  89.  31. 129.  83. 275.  65. 198. 236. 253. 124.  44. 172.\n",
      " 114. 142. 109. 180. 144. 163. 147.  97. 220. 190. 109. 191. 122. 230.\n",
      " 242. 248. 249. 192. 131. 237.  78. 135. 244. 199. 270. 164.  72.  96.\n",
      " 306.  91. 214.  95. 216. 263. 178. 113. 200. 139. 139.  88. 148.  88.\n",
      " 243.  71.  77. 109. 272.  60.  54. 221.  90. 311. 281. 182. 321.  58.\n",
      " 262. 206. 233. 242. 123. 167.  63. 197.  71. 168. 140. 217. 121. 235.\n",
      " 245.  40.  52. 104. 132.  88.  69. 219.  72. 201. 110.  51. 277.  63.\n",
      " 118.  69. 273. 258.  43. 198. 242. 232. 175.  93. 168. 275. 293. 281.\n",
      "  72. 140. 189. 181. 209. 136. 261. 113. 131. 174. 257.  55.  84.  42.\n",
      " 146. 212. 233.  91. 111. 152. 120.  67. 310.  94. 183.  66. 173.  72.\n",
      "  49.  64.  48. 178. 104. 132. 220.  57.]\n",
      "Score:  0.5177494254132934\n",
      "[  -9.96228958 -239.74191297  519.90178223  324.33049163 -783.36918479\n",
      "  469.75119728   97.15076946  176.00399634  747.93655335   67.6781432 ]\n",
      "Score: 0.5177489195463592\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "ds = datasets.load_diabetes()\n",
    "x=ds.data\n",
    "y=ds.target\n",
    "\n",
    "lr =LinearRegression()\n",
    "lr.fit(x,y)\n",
    "print(x,y)\n",
    "print('Score: ', lr.score(x,y))\n",
    "\n",
    "rd=Ridge(alpha=0.0001)\n",
    "rd.fit(x,y)\n",
    "print(rd.coef_)\n",
    "print('Score:', rd.score(x,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c10bfcd",
   "metadata": {},
   "source": [
    "## applying Gridsearch cv in Support vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a86a8b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9800000000000001\n",
      "linear\n",
      "{'alpha': 0.0001}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "parameters = {'kernel':('linear', 'poly', 'rbf'), 'C':[1,10]}\n",
    "svc = svm.SVC()\n",
    "clf = GridSearchCV(svc,parameters)\n",
    "clf.fit(iris.data,iris.target)\n",
    "#GridSearchCV(estimator=SVC(),\n",
    "             # param_grid = {'c':[1:10], 'Kernel': ('linear', 'poly', 'rbf')} )\n",
    "#sorted(clf.cv_results_.keys())\n",
    "\n",
    "print(clf.best_score_)\n",
    "print(clf.best_estimator_.kernel)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4bec61e",
   "metadata": {},
   "source": [
    "#### Apply Gridsearch cv's suggested values in the actual dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "efa4d7d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99\n"
     ]
    }
   ],
   "source": [
    "sv = svm.SVC(kernel='linear',C=1)\n",
    "sv.fit(iris.data,iris.target)\n",
    "t = sv.score(iris.data,iris.target)\n",
    "print(round(t,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5769163",
   "metadata": {},
   "source": [
    "## applying Gridsearch cv in DecisisonTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e379e59c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'gini'}\n",
      "0.9600000000000002\n",
      "0.96\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "dtc = DecisionTreeClassifier()\n",
    "iris=datasets.load_iris()\n",
    "\n",
    "grid_param = {'criterion': ['gini', 'entropy']}\n",
    "#gridk={'kernel':['linear', 'poly', 'rbf']}\n",
    "\n",
    "gd_sr = GridSearchCV(estimator =dtc,\n",
    "                      param_grid = grid_param,\n",
    "                      scoring = 'accuracy',\n",
    "                      cv=5)\n",
    "gd_sr.fit(iris.data,iris.target)\n",
    "\n",
    "best_paramters = gd_sr.best_params_\n",
    "print(best_paramters)\n",
    "best_result =gd_sr.best_score_\n",
    "print(best_result)\n",
    "print(round(best_result,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1a056c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier(criterion ='gini')\n",
    "dtc.fit(iris.data,iris.target)\n",
    "t = dtc.score(iris.data,iris.target)\n",
    "print(round(t,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b30cdab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV(estimator=Ridge(),\n",
      "                   param_distributions={'alpha': [1, 1.0, 0.01, 0.001, 0.0001,\n",
      "                                                  0]})\n",
      "0.4823231384163485\n",
      "0.0001\n"
     ]
    }
   ],
   "source": [
    "#Randomised Search CV for algorithm tuning\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "#Load dataset\n",
    "dataset = datasets.load_diabetes()\n",
    "\n",
    "#prepare a uniform distribution to sample for the alpha parameter\n",
    "param_grid= {'alpha': [1,1.0,0.01,0.001,0.0001,0]}\n",
    "#create and fit a ridge regression model, testing random alpha values\n",
    "model = Ridge()\n",
    "rsearch = RandomizedSearchCV(estimator= model, param_distributions = param_grid)\n",
    "rsearch.fit(dataset.data, dataset.target)\n",
    "print(rsearch)\n",
    "\n",
    "#summarise the results of the random parametersearch\n",
    "print(rsearch.best_score_)\n",
    "print(rsearch.best_estimator_.alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1446cdd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
